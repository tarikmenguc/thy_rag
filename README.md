# Turkish Technic RAG Assistant âœˆï¸

An **Adaptive RAG** application that answers questions based on the 2020â€“2023 annual reports of **Turkish Technic (TÃ¼rk Hava YollarÄ± Teknik A.Å.)**.

## ğŸ¯ Project Goal & Learnings

Built to learn and demonstrate modern Generative AI and RAG techniques.

**Topics Covered:**
- **RAG Architecture** â€” grounding LLM responses with retrieved document context
- **Vector Database** â€” storing and querying text chunk embeddings with ChromaDB
- **LangGraph** â€” stateful graph-based Adaptive RAG with nodes, edges, and loops
- **Vision AI** â€” extracting text from scanned PDFs using Groq Vision
- **Metadata Filtering** â€” year-based document filtering in ChromaDB
- **Conversational Memory** â€” context-aware follow-up questions using chat history
- **Re-Ranking** â€” selecting the most relevant documents with FlashRank

## ğŸ—ï¸ Architecture

```
User Question
      â”‚
      â–¼
 [retrieve]  â† Fetches relevant documents from ChromaDB (with year filter)
      â”‚
      â–¼
 [generate]  â† Generates an answer using Groq LLM
      â”‚
      â–¼
[grade_answer] â† Evaluates the answer: useful or not_useful?
      â”‚
      â”œâ”€â”€ useful     â†’ Return to user âœ…
      â””â”€â”€ not_useful â†’ Back to [retrieve] ğŸ”„ (max 2 retries)
```

## ğŸ› ï¸ Tech Stack

| Technology | Role |
|---|---|
| **LangGraph** | Adaptive RAG flow control (graph + conditional loop) |
| **LangChain** | Prompt templates, retrievers, chain composition |
| **Groq** (`llama-3.3-70b-versatile`) | Main language model |
| **Groq** (`llama-4-scout-17b`) | Vision model â€” OCR for scanned PDFs |
| **ChromaDB** | Vector database (1,078 chunks) |
| **HuggingFace** (`paraphrase-multilingual-MiniLM-L12-v2`) | Multilingual embeddings |
| **Streamlit** | Chat interface |
| **PyMuPDF** | PDF â†’ PNG conversion for vision OCR |
| **FlashRank** | Re-ranking retrieved documents |

## ğŸš€ Installation

```bash
# 1. Clone the repository
git clone https://github.com/tarikmenguc/thy_rag.git
cd thy_rag

# 2. Install dependencies
pip install langchain langchain-groq langchain-huggingface langchain-chroma
pip install chromadb pypdf sentence-transformers python-dotenv
pip install streamlit pymupdf pillow flashrank langgraph

# 3. Create a .env file
echo GROQ_API_KEY=gsk_... > .env

# 4. Ingest 2020-2021 PDFs (text-based)
python main.py

# 5. Ingest 2022-2023 PDFs (scanned â†’ Groq Vision OCR)
python ingest_scanned_pdfs.py

# 6. Run the application
streamlit run app.py
```

## ğŸ“‚ Project Structure

```
thy_rag/
â”œâ”€â”€ main.py                  # 2020-2021 PDF ingestion pipeline
â”œâ”€â”€ ingest_scanned_pdfs.py   # 2022-2023 scanned PDF ingestion (Groq Vision OCR)
â”œâ”€â”€ rag_graph.py             # LangGraph Adaptive RAG engine
â”œâ”€â”€ app.py                   # Streamlit chat interface
â”œâ”€â”€ project_journey.py       # Full project development journey (documentation)
â”œâ”€â”€ .env                     # API keys
â”œâ”€â”€ data/                    # Annual report PDFs (2020â€“2023)
â””â”€â”€ chroma_db_thy/           # Local vector database
```

## ğŸ’¬ Usage

Open the app, select the years to search in the left sidebar, and ask your questions:

- *"Which aircraft types were maintained in 2022?"*
- *"What is the staff count and title breakdown for 2023?"*
- *"What was the net profit in 2021? And what about 2020?"* â† memory support

## âš ï¸ Notes

- **Free Tier Limit:** Groq's free tier allows 100K tokens/day. Each question triggers 2 LLM calls (generate + grade).
- **2022â€“2023 Content:** These reports are operational, not financial â€” they cover technical activities, certifications, and client information.
- **Naming Conflict:** Do not name any file `langgraph.py` â€” it conflicts with the `langgraph` Python package.
